{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column (before handling):\n",
      "fr_orig           0\n",
      "dms_orig          0\n",
      "dms_dest          0\n",
      "fr_dest           0\n",
      "dms_mode          0\n",
      "                 ..\n",
      "fr_outmode_3.0    0\n",
      "fr_outmode_4.0    0\n",
      "fr_outmode_5.0    0\n",
      "fr_outmode_6.0    0\n",
      "fr_outmode_7.0    0\n",
      "Length: 64, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\om\\AppData\\Local\\Temp\\ipykernel_7216\\2603254151.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  regional_data[col].fillna(regional_data[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column (after handling):\n",
      "0\n",
      "\n",
      "Cleaned dataset saved to C:/project/Freight_Analysis_Framework-/data/processed/freight_analysis_cleaned.csv.\n"
     ]
    }
   ],
   "source": [
    "# Reload the dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the feature-engineered dataset from the processed folder\n",
    "feature_engineered_data_path = \"C:/project/Freight_Analysis_Framework-/data/processed/freight_analysis_feature_engineered.csv\"\n",
    "regional_data = pd.read_csv(feature_engineered_data_path)\n",
    "\n",
    "# Step 1: Identify Missing Values\n",
    "print(\"Missing values per column (before handling):\")\n",
    "print(regional_data.isnull().sum())\n",
    "\n",
    "# Step 2: Handle Missing Values\n",
    "# For numerical columns, fill with the column mean\n",
    "numerical_columns = regional_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "regional_data[numerical_columns] = regional_data[numerical_columns].fillna(regional_data[numerical_columns].mean())\n",
    "\n",
    "# For categorical columns, fill with the mode\n",
    "categorical_columns = regional_data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    regional_data[col].fillna(regional_data[col].mode()[0], inplace=True)\n",
    "\n",
    "# Step 3: Verify Missing Values\n",
    "print(\"\\nMissing values per column (after handling):\")\n",
    "print(regional_data.isnull().sum().sum())\n",
    "\n",
    "# Save the cleaned dataset back for modeling\n",
    "cleaned_data_path = \"C:/project/Freight_Analysis_Framework-/data/processed/freight_analysis_cleaned.csv\"\n",
    "regional_data.to_csv(cleaned_data_path, index=False)\n",
    "print(f\"\\nCleaned dataset saved to {cleaned_data_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the cleaned dataset:\n",
      "   fr_orig  dms_orig  dms_dest  fr_dest  dms_mode  sctg2  trade_type  \\\n",
      "0    804.0        11        11    801.0         1      1           1   \n",
      "1    804.0        11        19    801.0         1      1           1   \n",
      "2    804.0        11       129    801.0         1      1           1   \n",
      "3    804.0        11       131    801.0         1      1           1   \n",
      "4    804.0        11       139    801.0         1      1           1   \n",
      "\n",
      "   tons_2012  tons_2013  tons_2014  ...  fr_inmode_4.0  fr_inmode_5.0  \\\n",
      "0     0.3231    18.2865    19.7980  ...          False          False   \n",
      "1     0.3231   218.1548   220.2783  ...          False          False   \n",
      "2     0.3231     0.8870     0.8371  ...          False          False   \n",
      "3     0.3231     6.5007     5.7015  ...          False          False   \n",
      "4     0.3231     2.8717     2.4586  ...          False          False   \n",
      "\n",
      "   fr_inmode_6.0  fr_inmode_7.0  fr_outmode_2.0  fr_outmode_3.0  \\\n",
      "0          False          False           False           False   \n",
      "1          False          False           False           False   \n",
      "2          False          False           False           False   \n",
      "3          False          False           False           False   \n",
      "4          False          False           False           False   \n",
      "\n",
      "   fr_outmode_4.0  fr_outmode_5.0  fr_outmode_6.0  fr_outmode_7.0  \n",
      "0            True           False           False           False  \n",
      "1            True           False           False           False  \n",
      "2            True           False           False           False  \n",
      "3            True           False           False           False  \n",
      "4            True           False           False           False  \n",
      "\n",
      "[5 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "# Reload the cleaned dataset\n",
    "cleaned_data_path = \"C:/project/Freight_Analysis_Framework-/data/processed/freight_analysis_cleaned.csv\"\n",
    "regional_data_cleaned = pd.read_csv(cleaned_data_path)\n",
    "\n",
    "# Check the first few rows to ensure it loaded correctly\n",
    "print(\"First few rows of the cleaned dataset:\")\n",
    "print(regional_data_cleaned.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Volume_Category_2012', 'Value_Category_2012']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_dtypes=regional_data_cleaned.dtypes\n",
    "object_columns=col_dtypes[col_dtypes=='object'].index.tolist()\n",
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after encoding object columns:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1660972 entries, 0 to 1660971\n",
      "Data columns (total 62 columns):\n",
      " #   Column                             Non-Null Count    Dtype  \n",
      "---  ------                             --------------    -----  \n",
      " 0   fr_orig                            1660972 non-null  float64\n",
      " 1   dms_orig                           1660972 non-null  int64  \n",
      " 2   dms_dest                           1660972 non-null  int64  \n",
      " 3   fr_dest                            1660972 non-null  float64\n",
      " 4   dms_mode                           1660972 non-null  int64  \n",
      " 5   sctg2                              1660972 non-null  int64  \n",
      " 6   trade_type                         1660972 non-null  int64  \n",
      " 7   tons_2012                          1660972 non-null  float64\n",
      " 8   tons_2013                          1660972 non-null  float64\n",
      " 9   tons_2014                          1660972 non-null  float64\n",
      " 10  tons_2015                          1660972 non-null  float64\n",
      " 11  tons_2020                          1660972 non-null  float64\n",
      " 12  tons_2025                          1660972 non-null  float64\n",
      " 13  tons_2030                          1660972 non-null  float64\n",
      " 14  tons_2035                          1660972 non-null  float64\n",
      " 15  tons_2040                          1660972 non-null  float64\n",
      " 16  tons_2045                          1660972 non-null  float64\n",
      " 17  value_2012                         1660972 non-null  float64\n",
      " 18  value_2013                         1660972 non-null  float64\n",
      " 19  value_2014                         1660972 non-null  float64\n",
      " 20  value_2015                         1660972 non-null  float64\n",
      " 21  value_2020                         1660972 non-null  float64\n",
      " 22  value_2025                         1660972 non-null  float64\n",
      " 23  value_2030                         1660972 non-null  float64\n",
      " 24  value_2035                         1660972 non-null  float64\n",
      " 25  value_2040                         1660972 non-null  float64\n",
      " 26  value_2045                         1660972 non-null  float64\n",
      " 27  tmiles_2012                        1660972 non-null  float64\n",
      " 28  tmiles_2013                        1660972 non-null  float64\n",
      " 29  tmiles_2014                        1660972 non-null  float64\n",
      " 30  tmiles_2015                        1660972 non-null  float64\n",
      " 31  tmiles_2020                        1660972 non-null  float64\n",
      " 32  tmiles_2025                        1660972 non-null  float64\n",
      " 33  tmiles_2030                        1660972 non-null  float64\n",
      " 34  tmiles_2035                        1660972 non-null  float64\n",
      " 35  tmiles_2040                        1660972 non-null  float64\n",
      " 36  tmiles_2045                        1660972 non-null  float64\n",
      " 37  curval_2013                        1660972 non-null  float64\n",
      " 38  curval_2014                        1660972 non-null  float64\n",
      " 39  curval_2015                        1660972 non-null  float64\n",
      " 40  Volume_Growth_2012_2013            1660972 non-null  float64\n",
      " 41  Volume_Growth_2013_2014            1660972 non-null  float64\n",
      " 42  Volume_Growth_2014_2015            1660972 non-null  float64\n",
      " 43  Value_Growth_2012_2013             1660972 non-null  float64\n",
      " 44  Value_Growth_2013_2014             1660972 non-null  float64\n",
      " 45  Value_Growth_2014_2015             1660972 non-null  float64\n",
      " 46  Log_Freight_Volume_2012            1660972 non-null  float64\n",
      " 47  Log_Freight_Value_2012             1660972 non-null  float64\n",
      " 48  Volume_Value_Interaction_2012      1660972 non-null  float64\n",
      " 49  Log_Volume_Value_Interaction_2012  1660972 non-null  float64\n",
      " 50  fr_inmode_2.0                      1660972 non-null  bool   \n",
      " 51  fr_inmode_3.0                      1660972 non-null  bool   \n",
      " 52  fr_inmode_4.0                      1660972 non-null  bool   \n",
      " 53  fr_inmode_5.0                      1660972 non-null  bool   \n",
      " 54  fr_inmode_6.0                      1660972 non-null  bool   \n",
      " 55  fr_inmode_7.0                      1660972 non-null  bool   \n",
      " 56  fr_outmode_2.0                     1660972 non-null  bool   \n",
      " 57  fr_outmode_3.0                     1660972 non-null  bool   \n",
      " 58  fr_outmode_4.0                     1660972 non-null  bool   \n",
      " 59  fr_outmode_5.0                     1660972 non-null  bool   \n",
      " 60  fr_outmode_6.0                     1660972 non-null  bool   \n",
      " 61  fr_outmode_7.0                     1660972 non-null  bool   \n",
      "dtypes: bool(12), float64(45), int64(5)\n",
      "memory usage: 652.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the object columns\n",
    "regional_data_cleaned = pd.get_dummies(regional_data_cleaned, columns=['Volume_Category_2012', 'Value_Category_2012'], drop_first=True)\n",
    "\n",
    "# Verify the changes\n",
    "print(\"Dataset after encoding object columns:\")\n",
    "print(regional_data_cleaned.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_dtypes=regional_data_cleaned.dtypes\n",
    "object_columns=col_dtypes[col_dtypes=='object'].index.tolist()\n",
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X) shape: (1660972, 61)\n",
      "Target (y) shape: (1660972,)\n",
      "Training set shape: X_train: (1328777, 61), y_train: (1328777,)\n",
      "Testing set shape: X_test: (332195, 61), y_test: (332195,)\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = regional_data_cleaned.drop(columns=['value_2012'])  # Assuming 'value_2012' is the target\n",
    "y = regional_data_cleaned['value_2012']\n",
    "\n",
    "# Perform train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Output shapes of the datasets\n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"Target (y) shape: {y.shape}\")\n",
    "print(f\"Training set shape: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Testing set shape: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infinite values in X_train: 979115\n",
      "Infinite values in X_train (after handling): 0\n",
      "Missing values in X_train (after handling): 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check for infinite values in X_train\n",
    "print(\"Infinite values in X_train:\", np.isinf(X_train).sum().sum())\n",
    "\n",
    "# Replace infinite values with NaN, then fill NaN with the column mean\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fill NaN values with the mean of the column\n",
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "X_test.fillna(X_test.mean(), inplace=True)\n",
    "\n",
    "# Verify the data again\n",
    "print(\"Infinite values in X_train (after handling):\", np.isinf(X_train).sum().sum())\n",
    "print(\"Missing values in X_train (after handling):\", X_train.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 0.0597\n",
      "Linear Regression R²: 0.9948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model (fixing the error)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # Calculate RMSE directly\n",
    "r2 = r2_score(y_test, y_pred)  # Calculate R-squared\n",
    "\n",
    "# Output the evaluation metrics\n",
    "print(f\"Linear Regression RMSE: {rmse:.4f}\")  # Format RMSE to 4 decimal places\n",
    "print(f\"Linear Regression R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "freig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
